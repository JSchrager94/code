{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "#There is only one extra step: you need to transform the array of inputs to include non-linear terms such as ğ‘¥Â².\n",
    "\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Now you have the input and output in a suitable format. \n",
    "#Keep in mind that you need the input to be a two-dimensional array. Thatâ€™s why .reshape() is used.\n",
    "\n",
    "\n",
    "x = np.array([5, 15, 25, 35, 45, 55]).reshape((-1, 1))\n",
    "y = np.array([15, 11, 2, 8, 25, 32])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "#This is the new step you need to implement for polynomial regression!\n",
    "\n",
    "#As youâ€™ve seen earlier, you need to include ğ‘¥Â² (and perhaps other terms) as additional features when implementing polynomial regression. For that reason, you should transform the input array x to contain the additional column(s) with the values of ğ‘¥Â² (and eventually more features).\n",
    "\n",
    "#Itâ€™s possible to transform the input array in several ways (like using insert() from numpy), but the class PolynomialFeatures is very convenient for this purpose. Letâ€™s create an instance of this class:\n",
    "\n",
    "transformer = PolynomialFeatures(degree=2, include_bias=False)\n",
    "\n",
    "#The variable transformer refers to an instance of PolynomialFeatures which you can use to transform the input x.\n",
    "\n",
    "#You can provide several optional parameters to PolynomialFeatures:\n",
    "\n",
    "#degree is an integer (2 by default) that represents the degree of the polynomial regression function.\n",
    "#interaction_only is a Boolean (False by default) that decides whether to include only interaction features (True) or all features (False).\n",
    "#include_bias is a Boolean (True by default) that decides whether to include the bias (intercept) column of ones (True) or not (False).\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PolynomialFeatures(include_bias=False)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#This example uses the default values of all parameters, but youâ€™ll sometimes want to experiment with the degree of the function, and it can be beneficial to provide this argument anyway.\n",
    "\n",
    "#Before applying transformer, you need to fit it with .fit():\n",
    "\n",
    "transformer.fit(x)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Once transformer is fitted, itâ€™s ready to create a new, modified input. You apply .transform() to do that:\n",
    "x_ = transformer.transform(x)\n",
    "\n",
    "#Thatâ€™s the transformation of the input array with .transform(). It takes the input array as the argument and returns the modified array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can also use .fit_transform() to replace the three previous statements with only one:\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[   5.   25.]\n",
      " [  15.  225.]\n",
      " [  25.  625.]\n",
      " [  35. 1225.]\n",
      " [  45. 2025.]\n",
      " [  55. 3025.]]\n"
     ]
    }
   ],
   "source": [
    "#Thatâ€™s fitting and transforming the input array in one statement with .fit_transform(). \n",
    "#It also takes the input array and effectively does the same thing as .fit() and .transform() called in that order. \n",
    "#It also returns the modified array. This is how the new input array looks:\n",
    "\n",
    "print(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = LinearRegression().fit(x_, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8908516262498563\n",
      "intercept: 21.372321428571418\n",
      "coefficients: [-1.32357143  0.02839286]\n"
     ]
    }
   ],
   "source": [
    "#Again, .score() returns ğ‘…Â². Its first argument is also the modified input x_, not x. \n",
    "#The values of the weights are associated to .intercept_ and .coef_: .intercept_ represents ğ‘â‚€, while .coef_ references the array that contains ğ‘â‚ and ğ‘â‚‚ respectively.\n",
    "\n",
    "\n",
    "\n",
    "r_sq = model.score(x_, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('coefficients:', model.coef_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can obtain a very similar result with different transformation and regression arguments:\n",
    "\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=True).fit_transform(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1.000e+00 5.000e+00 2.500e+01]\n",
      " [1.000e+00 1.500e+01 2.250e+02]\n",
      " [1.000e+00 2.500e+01 6.250e+02]\n",
      " [1.000e+00 3.500e+01 1.225e+03]\n",
      " [1.000e+00 4.500e+01 2.025e+03]\n",
      " [1.000e+00 5.500e+01 3.025e+03]]\n"
     ]
    }
   ],
   "source": [
    "#This is how the modified input array looks in this case:\n",
    "\n",
    "print(x_)\n",
    "\n",
    "#The first column of x_ contains ones, the second has the values of x, while the third holds the squares of x."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The intercept is already included with the leftmost column of ones, and you donâ€™t need to include it again \n",
    "#when creating the instance of LinearRegression. Thus, you can provide fit_intercept=False. \n",
    "#This is how the next statement looks:\n",
    "\n",
    "model = LinearRegression(fit_intercept=False).fit(x_, y)\n",
    "    \n",
    "    \n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.8908516262498565\n",
      "intercept: 0.0\n",
      "coefficients: [21.37232143 -1.32357143  0.02839286]\n"
     ]
    }
   ],
   "source": [
    "r_sq = model.score(x_, y)\n",
    "print('coefficient of determination:', r_sq)\n",
    "print('intercept:', model.intercept_)\n",
    "print('coefficients:', model.coef_)\n",
    "\n",
    "#ou see that now .intercept_ is zero, but .coef_ actually contains ğ‘â‚€ as its first element. Everything else is the same."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicted response:\n",
      "[15.46428571  7.90714286  6.02857143  9.82857143 19.30714286 34.46428571]\n"
     ]
    }
   ],
   "source": [
    "#If you want to get the predicted response, just use .predict(), but remember that the argument should be the modified input x_ instead of the old x:\n",
    "\n",
    "y_pred = model.predict(x_)\n",
    "print('predicted response:', y_pred, sep='\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "#You can apply the identical procedure if you have several input variables. Youâ€™ll have an input array with more than one column, but everything else is the same. Here is an example:\n",
    "\n",
    "# Step 1: Import packages\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.preprocessing import PolynomialFeatures\n",
    "\n",
    "# Step 2a: Provide data\n",
    "x = [[0, 1], [5, 1], [15, 2], [25, 5], [35, 11], [45, 15], [55, 34], [60, 35]]\n",
    "y = [4, 5, 20, 14, 32, 22, 38, 43]\n",
    "x, y = np.array(x), np.array(y)\n",
    "\n",
    "# Step 2b: Transform input data\n",
    "x_ = PolynomialFeatures(degree=2, include_bias=False).fit_transform(x)\n",
    "\n",
    "# Step 3: Create a model and fit it\n",
    "model = LinearRegression().fit(x_, y)\n",
    "\n",
    "# Step 4: Get results\n",
    "r_sq = model.score(x_, y)\n",
    "intercept, coefficients = model.intercept_, model.coef_\n",
    "\n",
    "# Step 5: Predict\n",
    "y_pred = model.predict(x_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "coefficient of determination: 0.9453701449127819\n",
      "intercept: 0.8430556452395876\n",
      "coefficients:\n",
      "[ 2.44828275  0.16160353 -0.15259677  0.47928683 -0.4641851 ]\n",
      "predicted response:\n",
      "[ 0.54047408 11.36340283 16.07809622 15.79139    29.73858619 23.50834636\n",
      " 39.05631386 41.92339046]\n"
     ]
    }
   ],
   "source": [
    "print('coefficient of determination:', r_sq)\n",
    "\n",
    "print('intercept:', intercept)\n",
    "\n",
    "print('coefficients:', coefficients, sep='\\n')\n",
    "\n",
    "print('predicted response:', y_pred, sep='\\n')\n",
    "\n",
    "\n",
    "#In this case, there are six regression coefficients (including the intercept), as shown in the estimated regression function ğ‘“(ğ‘¥â‚, ğ‘¥â‚‚) = ğ‘â‚€ + ğ‘â‚ğ‘¥â‚ + ğ‘â‚‚ğ‘¥â‚‚ + ğ‘â‚ƒğ‘¥â‚Â² + ğ‘â‚„ğ‘¥â‚ğ‘¥â‚‚ + ğ‘â‚…ğ‘¥â‚‚Â².\n",
    "\n",
    "#You can also notice that polynomial regression yielded a higher coefficient of determination than multiple linear regression for the same problem. At first, you could think that obtaining such a large ğ‘…Â² is an excellent result. It might be.\n",
    "\n",
    "#However, in real-world situations, having a complex model and ğ‘…Â² very close to 1 might also be a sign of overfitting. To check the performance of a model, you should test it with new data, that is with observations not used to fit (train) the model.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
